{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a540eae6bd7fb62",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28a8f690bcf70c4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T19:52:50.377577800Z",
     "start_time": "2024-03-13T19:52:30.037131800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import itertools\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import tensorflow \n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.layers import Flatten, Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, AveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "\n",
    "import scikeras\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aa7a41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T17:47:18.728734100Z",
     "start_time": "2024-03-13T17:47:18.728734100Z"
    }
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63c4fc5db78aa0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T17:48:09.694986900Z",
     "start_time": "2024-03-13T17:48:08.719427900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_type_idx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bkl</th>\n",
       "      <td>1099</td>\n",
       "      <td>1099</td>\n",
       "      <td>1099</td>\n",
       "      <td>1089</td>\n",
       "      <td>1099</td>\n",
       "      <td>1099</td>\n",
       "      <td>1099</td>\n",
       "      <td>1099</td>\n",
       "      <td>1099</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df</th>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1111</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>6705</td>\n",
       "      <td>6705</td>\n",
       "      <td>6705</td>\n",
       "      <td>6660</td>\n",
       "      <td>6705</td>\n",
       "      <td>6705</td>\n",
       "      <td>6705</td>\n",
       "      <td>6705</td>\n",
       "      <td>6705</td>\n",
       "      <td>6705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vasc</th>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lesion_id  image_id  dx_type   age   sex  localization  dataset  path  \\\n",
       "dx                                                                             \n",
       "akiec        327       327      327   327   327           327      327   327   \n",
       "bcc          514       514      514   514   514           514      514   514   \n",
       "bkl         1099      1099     1099  1089  1099          1099     1099  1099   \n",
       "df           115       115      115   115   115           115      115   115   \n",
       "mel         1113      1113     1113  1111  1113          1113     1113  1113   \n",
       "nv          6705      6705     6705  6660  6705          6705     6705  6705   \n",
       "vasc         142       142      142   142   142           142      142   142   \n",
       "\n",
       "       cell_type  cell_type_idx  \n",
       "dx                               \n",
       "akiec        327            327  \n",
       "bcc          514            514  \n",
       "bkl         1099           1099  \n",
       "df           115            115  \n",
       "mel         1113           1113  \n",
       "nv          6705           6705  \n",
       "vasc         142            142  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesion_type_dict = {'akiec': 'Actinic keratoses',\n",
    "                    'bcc': 'Basal cell carcinoma',\n",
    "                    'bkl': 'Benign keratosis-like lesions ',\n",
    "                    'df': 'Dermatofibroma',\n",
    "                    'nv': 'Melanocytic nevi',\n",
    "                    'mel': 'Melanoma',\n",
    "                    'vasc': 'Vascular lesions'}\n",
    "\n",
    "path1 = \"C:\\\\Users\\\\THANOS\\\\Desktop\\\\DSDM\\\\PERIOD 4\\\\DF\\\\ASSIGNMENT\\\\dataverse_files\\\\HAM10000_images_part_1\" # HAM10000_images_part_1 path\n",
    "path2 = \"C:\\\\Users\\\\THANOS\\\\Desktop\\\\DSDM\\\\PERIOD 4\\\\DF\\\\ASSIGNMENT\\\\dataverse_files\\\\HAM10000_images_part_2\" # HAM10000_images_part_2 path\n",
    "path3 = \"C:\\\\Users\\\\THANOS\\\\Desktop\\\\DSDM\\\\PERIOD 4\\\\DF\\\\ASSIGNMENT\\\\dataverse_files\\\\HAM10000_metadata.csv\" # HAM10000_metadata.csv path\n",
    "\n",
    "imageid_path_dict = {}\n",
    "for path in [path1, path2]:\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\"):\n",
    "                imageid_path_dict[os.path.splitext(file)[0]] = os.path.join(root, file)\n",
    "\n",
    "skin_df = pd.read_csv(path3)\n",
    "skin_df['path'] = skin_df['image_id'].map(imageid_path_dict.get)\n",
    "skin_df['cell_type'] = skin_df['dx'].map(lesion_type_dict.get)\n",
    "skin_df['cell_type_idx'] = pd.Categorical(skin_df['cell_type']).codes\n",
    "skin_df.groupby(['dx']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54d5b001faf1c871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T17:48:17.940083300Z",
     "start_time": "2024-03-13T17:48:17.842643400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_type_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>HAM_0002867</td>\n",
       "      <td>ISIC_0033084</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...</td>\n",
       "      <td>Actinic keratoses</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>HAM_0002867</td>\n",
       "      <td>ISIC_0033550</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...</td>\n",
       "      <td>Actinic keratoses</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>HAM_0002867</td>\n",
       "      <td>ISIC_0033536</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...</td>\n",
       "      <td>Actinic keratoses</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>HAM_0000239</td>\n",
       "      <td>ISIC_0032854</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...</td>\n",
       "      <td>Actinic keratoses</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>HAM_0003521</td>\n",
       "      <td>ISIC_0032258</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...</td>\n",
       "      <td>Melanoma</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10015 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lesion_id      image_id     dx dx_type   age     sex localization  \\\n",
       "0      HAM_0000118  ISIC_0027419    bkl   histo  80.0    male        scalp   \n",
       "1      HAM_0000118  ISIC_0025030    bkl   histo  80.0    male        scalp   \n",
       "2      HAM_0002730  ISIC_0026769    bkl   histo  80.0    male        scalp   \n",
       "3      HAM_0002730  ISIC_0025661    bkl   histo  80.0    male        scalp   \n",
       "4      HAM_0001466  ISIC_0031633    bkl   histo  75.0    male          ear   \n",
       "...            ...           ...    ...     ...   ...     ...          ...   \n",
       "10010  HAM_0002867  ISIC_0033084  akiec   histo  40.0    male      abdomen   \n",
       "10011  HAM_0002867  ISIC_0033550  akiec   histo  40.0    male      abdomen   \n",
       "10012  HAM_0002867  ISIC_0033536  akiec   histo  40.0    male      abdomen   \n",
       "10013  HAM_0000239  ISIC_0032854  akiec   histo  80.0    male         face   \n",
       "10014  HAM_0003521  ISIC_0032258    mel   histo  70.0  female         back   \n",
       "\n",
       "            dataset                                               path  \\\n",
       "0      vidir_modern  C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...   \n",
       "1      vidir_modern  C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...   \n",
       "2      vidir_modern  C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...   \n",
       "3      vidir_modern  C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...   \n",
       "4      vidir_modern  C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...   \n",
       "...             ...                                                ...   \n",
       "10010  vidir_modern  C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...   \n",
       "10011  vidir_modern  C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...   \n",
       "10012  vidir_modern  C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...   \n",
       "10013  vidir_modern  C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...   \n",
       "10014  vidir_modern  C:\\Users\\THANOS\\Desktop\\DSDM\\PERIOD 4\\DF\\ASSIG...   \n",
       "\n",
       "                            cell_type  cell_type_idx  \n",
       "0      Benign keratosis-like lesions               2  \n",
       "1      Benign keratosis-like lesions               2  \n",
       "2      Benign keratosis-like lesions               2  \n",
       "3      Benign keratosis-like lesions               2  \n",
       "4      Benign keratosis-like lesions               2  \n",
       "...                               ...            ...  \n",
       "10010               Actinic keratoses              0  \n",
       "10011               Actinic keratoses              0  \n",
       "10012               Actinic keratoses              0  \n",
       "10013               Actinic keratoses              0  \n",
       "10014                        Melanoma              5  \n",
       "\n",
       "[10015 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9057aff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make sure there are no missing values or NaNs in your input data\n",
    "\n",
    "skin_df['age'].fillna(int(skin_df['age'].mean()),inplace=True)\n",
    "\n",
    "unknown_indices = skin_df[skin_df['sex'] == 'unknown'].index\n",
    "unknown_count = len(unknown_indices)\n",
    "replacement_values = np.random.choice(['male', 'female'], unknown_count)\n",
    "skin_df.loc[unknown_indices, 'sex'] = replacement_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8337eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lesion_id        0\n",
       "image_id         0\n",
       "dx               0\n",
       "dx_type          0\n",
       "age              0\n",
       "sex              0\n",
       "localization     0\n",
       "dataset          0\n",
       "path             0\n",
       "cell_type        0\n",
       "cell_type_idx    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skin_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d609d86f22a08091",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T17:51:50.038233500Z",
     "start_time": "2024-03-13T17:49:05.395418600Z"
    }
   },
   "outputs": [],
   "source": [
    "skin_df['image'] = skin_df['path'].map(lambda x: np.asarray(Image.open(x).resize((75,100))))\n",
    "X=skin_df.drop(columns=['cell_type_idx'],axis=1)\n",
    "y=skin_df['cell_type_idx']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6681d9c72de9e9c2",
   "metadata": {},
   "source": [
    "# Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "803c601b2ade45b0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-13T17:51:50.022596500Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_o, x_test_o, y_train_o, y_test_o = train_test_split(X, y, test_size=0.2,random_state=666)\n",
    "x_train = np.asarray(x_train_o['image'].tolist())\n",
    "x_test = np.asarray(x_test_o['image'].tolist())\n",
    "x_train_mean = np.mean(x_train)\n",
    "x_train_std = np.std(x_train)\n",
    "x_test_mean = np.mean(x_test)\n",
    "x_test_std = np.std(x_test)\n",
    "x_train = (x_train - x_train_mean)/x_train_std\n",
    "x_test = (x_test - x_test_mean)/x_test_std\n",
    "y_train = to_categorical(y_train_o, num_classes = 7)\n",
    "y_test = to_categorical(y_test_o, num_classes = 7)\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.1, random_state = 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8197a7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T17:51:50.049288100Z",
     "start_time": "2024-03-13T17:51:50.049288100Z"
    }
   },
   "source": [
    "#Reshaping the Images into 3 channels (RGB)\n",
    "x_train = x_train.reshape(x_train.shape[0], *(75, 100, 3))\n",
    "x_test = x_test.reshape(x_test.shape[0], *(75, 100, 3))\n",
    "x_validate = x_validate.reshape(x_validate.shape[0], *(75, 100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76ea1e1646b4cd1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T17:51:50.049288100Z",
     "start_time": "2024-03-13T17:51:50.049288100Z"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "#input_shape = (75, 100, 3)\n",
    "num_classes = 7\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=4, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "#Data Generation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91b9543ab8419a5",
   "metadata": {},
   "source": [
    "# Basic CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52aaf693700e7f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 100, 75, 32)       896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 100, 75, 64)       18496     \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 50, 37, 64)        0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50, 37, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 50, 37, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 50, 37, 64)        36928     \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 25, 18, 64)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 25, 18, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 25, 18, 64)        36928     \n",
      "                                                                 \n",
      " average_pooling2d_2 (Avera  (None, 12, 9, 64)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 12, 9, 64)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 9, 64)         36928     \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 12, 9, 64)         36928     \n",
      "                                                                 \n",
      " average_pooling2d_3 (Avera  (None, 6, 4, 64)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 6, 4, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1536)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               196736    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 401671 (1.53 MB)\n",
      "Trainable params: 401671 (1.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "b_cnn = Sequential()\n",
    "b_cnn.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding = 'Same',input_shape=input_shape))\n",
    "b_cnn.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
    "b_cnn.add(AveragePooling2D(pool_size = (2, 2)))\n",
    "b_cnn.add(Dropout(0.25))\n",
    "b_cnn.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
    "b_cnn.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
    "b_cnn.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "b_cnn.add(Dropout(0.25))\n",
    "b_cnn.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
    "b_cnn.add(AveragePooling2D(pool_size = (2, 2)))\n",
    "b_cnn.add(Dropout(0.25))\n",
    "b_cnn.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
    "b_cnn.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
    "b_cnn.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "b_cnn.add(Dropout(0.25))\n",
    "b_cnn.add(Flatten())\n",
    "b_cnn.add(Dense(128, activation='relu'))\n",
    "b_cnn.add(Activation('relu'))\n",
    "b_cnn.add(Dropout(0.25))\n",
    "b_cnn.add(Dense(num_classes, activation='softmax'))\n",
    "b_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "931a049921f24b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\THANOS\\AppData\\Local\\Temp\\ipykernel_11976\\3277338296.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  b_cnn_history = b_cnn.fit_generator(datagen.flow(x_train,y_train, batch_size=16),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1154, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 544, in minimize\n        self.apply_gradients(grads_and_vars)\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1223, in apply_gradients\n        return super().apply_gradients(grads_and_vars, name=name)\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 652, in apply_gradients\n        iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1253, in _internal_apply_gradients\n        return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1345, in _distributed_apply_gradients_fn\n        distribution.extended.update(\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1342, in apply_grad_to_update_var  **\n        return self._update_step(grad, var)\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 241, in _update_step\n        self.update_step(gradient, variable)\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\adam.py\", line 204, in update_step\n        variable.assign_sub((m * alpha) / (tf.sqrt(v) + self.epsilon))\n\n    ValueError: None values not supported.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m b_cnn\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m optimizer , loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m b_cnn_history \u001b[38;5;241m=\u001b[39m b_cnn\u001b[38;5;241m.\u001b[39mfit_generator(datagen\u001b[38;5;241m.\u001b[39mflow(x_train,y_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m),\n\u001b[0;32m      3\u001b[0m                               epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m, validation_data \u001b[38;5;241m=\u001b[39m (x_validate,y_validate),\n\u001b[0;32m      4\u001b[0m                               verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, steps_per_epoch\u001b[38;5;241m=\u001b[39mx_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[0;32m      5\u001b[0m                               , callbacks\u001b[38;5;241m=\u001b[39m[learning_rate_reduction])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:2913\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2901\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2902\u001b[0m \n\u001b[0;32m   2903\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2904\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2905\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2906\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2907\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2908\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2909\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2910\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2911\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2912\u001b[0m )\n\u001b[1;32m-> 2913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m   2914\u001b[0m     generator,\n\u001b[0;32m   2915\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[0;32m   2916\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m   2917\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   2918\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   2919\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_data,\n\u001b[0;32m   2920\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m   2921\u001b[0m     validation_freq\u001b[38;5;241m=\u001b[39mvalidation_freq,\n\u001b[0;32m   2922\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39mclass_weight,\n\u001b[0;32m   2923\u001b[0m     max_queue_size\u001b[38;5;241m=\u001b[39mmax_queue_size,\n\u001b[0;32m   2924\u001b[0m     workers\u001b[38;5;241m=\u001b[39mworkers,\n\u001b[0;32m   2925\u001b[0m     use_multiprocessing\u001b[38;5;241m=\u001b[39muse_multiprocessing,\n\u001b[0;32m   2926\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m   2927\u001b[0m     initial_epoch\u001b[38;5;241m=\u001b[39minitial_epoch,\n\u001b[0;32m   2928\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filecpx1e0ut.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1154, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 544, in minimize\n        self.apply_gradients(grads_and_vars)\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1223, in apply_gradients\n        return super().apply_gradients(grads_and_vars, name=name)\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 652, in apply_gradients\n        iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1253, in _internal_apply_gradients\n        return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1345, in _distributed_apply_gradients_fn\n        distribution.extended.update(\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1342, in apply_grad_to_update_var  **\n        return self._update_step(grad, var)\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 241, in _update_step\n        self.update_step(gradient, variable)\n    File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\adam.py\", line 204, in update_step\n        variable.assign_sub((m * alpha) / (tf.sqrt(v) + self.epsilon))\n\n    ValueError: None values not supported.\n"
     ]
    }
   ],
   "source": [
    "b_cnn.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "b_cnn_history = b_cnn.fit_generator(datagen.flow(x_train,y_train, batch_size=16),\n",
    "                              epochs = 50, validation_data = (x_validate,y_validate),\n",
    "                              verbose = 1, steps_per_epoch=x_train.shape[0] // 16\n",
    "                              , callbacks=[learning_rate_reduction])\n",
    "\n",
    "# TODO: check if with alternative datagen if the error still exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732ba32c7feed732",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_cnn_loss, b_cnn_accuracy = b_cnn.evaluate(x_test, y_test, verbose=0)\n",
    "b_cnn_predictions = b_cnn.predict(x_test)\n",
    "b_cnn_loss_v, b_cnn_accuracy_v = b_cnn.evaluate(x_validate, y_validate, verbose=0)\n",
    "b_cnn_loss_t, b_cnn_accuracy_t = b_cnn.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"CNN Training: accuracy = %f\" % (b_cnn_accuracy_t))\n",
    "print(\"CNN Validation: accuracy = %f\" % (b_cnn_accuracy_v))\n",
    "print(\"CNN Test: accuracy = %f\" % (b_cnn_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d83e86937fe18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(b_cnn_history.b_cnn_history['accuracy'])\n",
    "plt.plot(b_cnn_history.b_cnn_history['val_accuracy'])\n",
    "plt.title('CNN Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Test', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4c59f71d6b71d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_cnn_predictions = np.array(list(map(lambda x: np.argmax(x), b_cnn_predictions)))\n",
    "categories = ['Actinic keratoses',\n",
    "              'Basal cell carcinoma',\n",
    "              'Benign keratosis-like lesions ', \n",
    "              'Dermatofibroma', \n",
    "              'Melanocytic nevi', \n",
    "              'Melanoma',\n",
    "              'Vascular lesions']\n",
    "\n",
    "CMatrix = pd.DataFrame(confusion_matrix(y_test_o, b_cnn_predictions), columns=categories, index =categories)\n",
    "plt.figure(figsize=(12, 6)) \n",
    "ax = sns.heatmap(CMatrix, annot = True, fmt = 'g' ,vmin = 0, vmax = 10,cmap = 'bone_r') \n",
    "ax.set_xlabel('Predicted',fontsize = 14,weight = 'bold') \n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation =90); \n",
    "ax.set_ylabel('Actual',fontsize = 14,weight = 'bold')\n",
    "ax.set_title('Confusion Matrix - Test Set',fontsize = 16,weight = 'bold',pad=20);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b22de5",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d05650b405bbfc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 17, 23, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 17, 23, 96)        384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 8, 11, 96)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 8, 11, 256)        614656    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 8, 11, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 3, 5, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 3, 5, 384)         885120    \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 3, 5, 384)         1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 3, 5, 384)         147840    \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 3, 5, 384)         1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 3, 5, 256)         98560     \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 3, 5, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 1, 2, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4096)              2101248   \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24766184 (94.48 MB)\n",
      "Trainable params: 24763432 (94.46 MB)\n",
      "Non-trainable params: 2752 (10.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#AlexNet Model\n",
    "\n",
    "alexnet= keras.models.Sequential([\n",
    "keras.layers.Conv2D(filters=96,kernel_size=(11,11),strides=(4,4),activation='relu',\n",
    "                    input_shape=(75,100,3)),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "keras.layers.Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),activation='relu',padding=\"same\"),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "keras.layers.Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),activation='relu',padding=\"same\"),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Conv2D(filters=384,kernel_size=(1,1),strides=(1,1),activation='relu',padding=\"same\"),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Conv2D(filters=256,kernel_size=(1,1),strides=(1,1),activation='relu',padding=\"same\"),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),keras.layers.Flatten(),\n",
    "keras.layers.Dense(4096, activation='relu'),keras.layers.Dropout(0.5),\n",
    "keras.layers.Dense(4096, activation='relu'),keras.layers.Dropout(0.5),\n",
    "keras.layers.Dense(1000, activation='softmax')])\n",
    "alexnet.compile(loss='sparse_categorical_crossentropy',optimizer=tensorflow.optimizers.SGD(learning_ra=0.001),\n",
    "               metrics=['accuracy'])\n",
    "alexnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "865dbb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\THANOS\\AppData\\Local\\Temp\\ipykernel_11976\\608476484.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  alexnet_history =alexnet.fit_generator(datagen.flow(x_train,y_train, batch_size=16),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n\n  File \"C:\\Users\\THANOS\\AppData\\Local\\Temp\\ipykernel_11976\\608476484.py\", line 1, in <module>\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2913, in fit_generator\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py\", line 5775, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [16,1000] and labels shape [112]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_3427]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m alexnet_history \u001b[38;5;241m=\u001b[39malexnet\u001b[38;5;241m.\u001b[39mfit_generator(datagen\u001b[38;5;241m.\u001b[39mflow(x_train,y_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m),\n\u001b[0;32m      2\u001b[0m                               epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m, validation_data \u001b[38;5;241m=\u001b[39m (x_validate,y_validate),\n\u001b[0;32m      3\u001b[0m                               verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, steps_per_epoch\u001b[38;5;241m=\u001b[39mx_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[0;32m      4\u001b[0m                               , callbacks\u001b[38;5;241m=\u001b[39m[learning_rate_reduction])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:2913\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2901\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2902\u001b[0m \n\u001b[0;32m   2903\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2904\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2905\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2906\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2907\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2908\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2909\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2910\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2911\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2912\u001b[0m )\n\u001b[1;32m-> 2913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m   2914\u001b[0m     generator,\n\u001b[0;32m   2915\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[0;32m   2916\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m   2917\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   2918\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   2919\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_data,\n\u001b[0;32m   2920\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m   2921\u001b[0m     validation_freq\u001b[38;5;241m=\u001b[39mvalidation_freq,\n\u001b[0;32m   2922\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39mclass_weight,\n\u001b[0;32m   2923\u001b[0m     max_queue_size\u001b[38;5;241m=\u001b[39mmax_queue_size,\n\u001b[0;32m   2924\u001b[0m     workers\u001b[38;5;241m=\u001b[39mworkers,\n\u001b[0;32m   2925\u001b[0m     use_multiprocessing\u001b[38;5;241m=\u001b[39muse_multiprocessing,\n\u001b[0;32m   2926\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m   2927\u001b[0m     initial_epoch\u001b[38;5;241m=\u001b[39minitial_epoch,\n\u001b[0;32m   2928\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n\n  File \"C:\\Users\\THANOS\\AppData\\Local\\Temp\\ipykernel_11976\\608476484.py\", line 1, in <module>\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2913, in fit_generator\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\THANOS\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py\", line 5775, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [16,1000] and labels shape [112]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_3427]"
     ]
    }
   ],
   "source": [
    "alexnet_history =alexnet.fit_generator(datagen.flow(x_train,y_train, batch_size=16),\n",
    "                              epochs = 50, validation_data = (x_validate,y_validate),\n",
    "                              verbose = 1, steps_per_epoch=x_train.shape[0] // 16\n",
    "                              , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1725b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_loss, alexnet_accuracy = alexnet.evaluate(x_test, y_test, verbose=0)\n",
    "alexnet_predictions = alexnet.predict(x_test)\n",
    "alexnet_loss_v, alexnet_accuracy_v = alexnet.evaluate(x_validate, y_validate, verbose=0)\n",
    "alexnet_loss_t, alexnet_accuracy_t = alexnet.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"CNN Training: accuracy = %f\" % (alexnet_accuracy_t))\n",
    "print(\"CNN Validation: accuracy = %f\" % (alexnet_accuracy_v))\n",
    "print(\"CNN Test: accuracy = %f\" % (alexnet_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6090a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alexnet_history.alexnet_history['accuracy'])\n",
    "plt.plot(alexnet_history.alexnet_history['val_accuracy'])\n",
    "plt.title('CNN Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Test', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879876b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_predictions = np.array(list(map(lambda x: np.argmax(x), alexnet_predictions)))\n",
    "categories = ['Actinic keratoses',\n",
    "              'Basal cell carcinoma',\n",
    "              'Benign keratosis-like lesions ', \n",
    "              'Dermatofibroma', \n",
    "              'Melanocytic nevi', \n",
    "              'Melanoma',\n",
    "              'Vascular lesions']\n",
    "\n",
    "CMatrix = pd.DataFrame(confusion_matrix(y_test_o, alexnet_predictions), columns=categories, index =categories)\n",
    "plt.figure(figsize=(12, 6)) \n",
    "ax = sns.heatmap(CMatrix, annot = True, fmt = 'g' ,vmin = 0, vmax = 10,cmap = 'bone_r') \n",
    "ax.set_xlabel('Predicted',fontsize = 14,weight = 'bold') \n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation =90); \n",
    "ax.set_ylabel('Actual',fontsize = 14,weight = 'bold')\n",
    "ax.set_title('Confusion Matrix - Test Set',fontsize = 16,weight = 'bold',pad=20);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72871f6",
   "metadata": {},
   "source": [
    "# ResNet (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b9fc2c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfastai\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fastai'"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "import pandas as pd\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.data.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = path3\n",
    "skin_df = pd.read_csv(csv_path)\n",
    "skin_df.sort_values(by=\"image_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af955fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_type_dict = {'akiec': 'Actinic keratoses',\n",
    "                    'bcc': 'Basal cell carcinoma',\n",
    "                    'bkl': 'Benign keratosis-like lesions ',\n",
    "                    'df': 'Dermatofibroma',\n",
    "                    'nv': 'Melanocytic nevi',\n",
    "                    'mel': 'Melanoma',\n",
    "                    'vasc': 'Vascular lesions'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9ba47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_class_dict = skin_df.loc[:, [\"image_id\", \"dx\"]] \n",
    "img_to_class_dict = img_to_class_dict.to_dict('list') \n",
    "img_to_class_dict = {img_id : lesion_type_dict[disease] for img_id,disease in zip(img_to_class_dict['image_id'], img_to_class_dict['dx']) }\n",
    "[x for x in img_to_class_dict.items()][:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d048b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_from_dict(path):\n",
    "    if 'path1' in str(path):  # Check if the path belongs to the first directory\n",
    "        return img_to_class_dict_path1[path.stem]\n",
    "    elif 'path2' in str(path):  # Check if the path belongs to the second directory\n",
    "        return img_to_class_dict_path2[path.stem]\n",
    "\n",
    "skin_db = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    item_tfms=[Resize(450), DihedralItem()],\n",
    "    batch_tfms=RandomResizedCrop(size=224, min_scale=0.75, max_scale=1.0),\n",
    "    get_items=get_image_files,\n",
    "    splitter=RandomSplitter(valid_pct=0.3, seed=42),\n",
    "    get_y=get_label_from_dict\n",
    ")\n",
    "\n",
    "img_path1 = path1  # Path to the first directory\n",
    "img_path2 = path2  # Path to the second directory\n",
    "\n",
    "# Get items from both directories and combine them\n",
    "items_path1 = get_image_files(img_path1)\n",
    "items_path2 = get_image_files(img_path2)\n",
    "combined_items = items_path1 + items_path2\n",
    "\n",
    "# Create DataLoader from combined items\n",
    "dls = skin_db.dataloaders(combined_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3130abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = cnn_learner(dls, resnet18, metrics=accuracy, opt_func=ranger)\n",
    "resnet.fine_tune(epochs=50, freeze_epochs=3, base_lr=0.005, cbs=MixUp(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bf2c93",
   "metadata": {},
   "source": [
    "# Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a43832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "input_shape=(75,100,3)\n",
    "baseModel = Xception(weights=\"imagenet\", include_top=False,input_shape=input_shape)\n",
    "#baseModel = ResNet50(weights=\"imagenet\", include_top=False,\n",
    "#input_tensor=Input(shape=(75,100,3)))\n",
    "#baseModel = Xception(weights=\"imagenet\", include_top=False,\n",
    "#input_tensor=Input(shape=(75,100,3)))\n",
    "#baseModel = EfficientNetB4(weights=\"imagenet\", include_top=False,\n",
    "#input_tensor=Input(shape=(75,100,3)))\n",
    "xcptn = baseModel.output\n",
    "xcptn = Flatten()(xcptn)\n",
    "xcptn = Dense(128, activation=\"relu\")(xcptn)\n",
    "xcptn = Dropout(0.2)(xcptn)\n",
    "xcptn = Dense(num_classes, activation=\"softmax\")(xcptn)\n",
    "xcptn = Model(inputs=baseModel.input, outputs=xcptn)\n",
    "xcptn.summary()\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c92ab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcptn.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "xcptn_history = xcptn.fit_generator(datagen.flow(x_train,y_train, batch_size=20),\n",
    "                              epochs = 50, validation_data = (x_validate,y_validate),\n",
    "                              verbose = 1, steps_per_epoch=x_train.shape[0] // 20\n",
    "                              , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcptn_loss, xcptn_accuracy = xcptn.evaluate(x_test, y_test, verbose=0)\n",
    "xcptn_predictions = xcptn.predict(x_test)\n",
    "xcptn_loss_v, xcptn_accuracy_v = xcptn.evaluate(x_validate, y_validate, verbose=0)\n",
    "xcptn_loss_t, xcptn_accuracy_t = xcptn.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training: accuracy = %f\" % (xcptn_accuracy_t))\n",
    "print(\"Validation: accuracy = %f\" % (xcptn_accuracy_v))\n",
    "print(\"Test: accuracy = %f\" % (xcptn_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b6039",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xcptn_history.xcptn_history['accuracy'])\n",
    "plt.plot(xcptn_history.xcptn_history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Test', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33094e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcptn_predictions = np.array(list(map(lambda x: np.argmax(x), xcptn_predictions)))\n",
    "categories = ['Actinic keratoses',\n",
    "              'Basal cell carcinoma',\n",
    "              'Benign keratosis-like lesions ', \n",
    "              'Dermatofibroma', \n",
    "              'Melanocytic nevi', \n",
    "              'Melanoma',\n",
    "              'Vascular lesions']\n",
    "\n",
    "CMatrix = pd.DataFrame(confusion_matrix(y_test_o, xcptn_predictions), columns=categories, index =categories)\n",
    "plt.figure(figsize=(12, 6)) \n",
    "ax = sns.heatmap(CMatrix, annot = True, fmt = 'g' ,vmin = 0, vmax = 10,cmap = 'bone_r') \n",
    "ax.set_xlabel('Predicted',fontsize = 14,weight = 'bold') \n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation =90); \n",
    "ax.set_ylabel('Actual',fontsize = 14,weight = 'bold')\n",
    "ax.set_title('Confusion Matrix - Test Set',fontsize = 16,weight = 'bold',pad=20);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5edcd61",
   "metadata": {},
   "source": [
    "*  #  High Fusion (Decision Fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10581d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Majority Voting\n",
    "\"\"\"--Hard Voting: Predict the class with the largest sum of votes from models\n",
    "   --Soft Voting: Predict the class with the largest summed probability from models\"\"\"\n",
    "fusion_1_hard = VotingClassifier(estimators=[('Basic CNN', b_cnn), ('AlexNet', alexnet), ('ResNet', resnet), ('Xception', xception)], voting='hard')\n",
    "fusion_1_hard.fit(x_train, y_train)\n",
    "fusion_1_hard.predict(x_test)  # Check sklearn documentation for more information\n",
    "\n",
    "fusion_1_soft = VotingClassifier(estimators=[('Basic CNN', b_cnn), ('AlexNet', alexnet), ('ResNet', resnet), ('Xception', xception)], voting='soft')\n",
    "fusion_1_soft.fit(x_train, y_train)\n",
    "fusion_1_soft.predict(x_test)  # Check sklearn documentation for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6f23e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Weighted Voting\n",
    "weights = {'Basic CNN': 1, 'AlexNet': 2, 'ResNet': 3, 'Xception': 4 }  # Example weights, adjust as needed\n",
    "fusion_2_hard_weighted = VotingClassifier(estimators=[('Basic CNN', b_cnn), ('AlexNet', alexnet), ('ResNet', resnet), ('Xception', xception)], voting='hard', weights=weights)\n",
    "fusion_2_hard_weighted.fit(X_train, y_train)\n",
    "fusion_2_hard_weighted.predict(X_test)\n",
    "\n",
    "weights = {'Basic CNN': 1, 'AlexNet': 2, 'ResNet': 3, 'Xception': 4 }  # Example weights, adjust as needed\n",
    "fusion_2_soft_weighted = VotingClassifier(estimators=[('Basic CNN', b_cnn), ('AlexNet', alexnet), ('ResNet', resnet), ('Xception', xception)], voting='soft', weights=weights)\n",
    "fusion_2_soft_weighted.fit(X_train, y_train)\n",
    "fusion_2_soft_weighted.predict(X_test)\n",
    "\n",
    "# TODO: how to select the weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057013ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Bayesian Consensus\n",
    "classifiers = [b_cnn, alexnet, resnet, xception] \n",
    "\n",
    "class_probs = []\n",
    "for clf in classifiers:\n",
    "    prob = clf.predict_proba(X_test)  \n",
    "    class_probs.append(prob)\n",
    "\n",
    "consensus_probs = np.prod(class_probs, axis=0) ** (1 / len(classifiers))\n",
    "final_predictions = np.argmax(consensus_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007b378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Dempster-Shafer's Theory of evidence\n",
    "from pyds import MassFunction\n",
    "classifiers = [b_cnn, alexnet, resnet, xception]  \n",
    "\n",
    "predictions = []\n",
    "for clf in classifiers:\n",
    "    pred = clf.predict(X_test)\n",
    "    predictions.append(pred)\n",
    "    \n",
    "bpas = [MassFunction({cls: confidence for cls, confidence in zip(np.unique(pred), clf.predict_proba(X_test))}) for pred, clf in zip(predictions, classifiers)]\n",
    "\n",
    "combined_bpa = bpas[0]\n",
    "for bpa in bpas[1:]:\n",
    "    combined_bpa = combined_bpa.combine(bpa)\n",
    "\n",
    "final_decision = combined_bpa.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9acec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate and Report performance of classifiers before and after applying fusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
